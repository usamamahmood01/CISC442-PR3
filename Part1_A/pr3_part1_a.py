# -*- coding: utf-8 -*-
"""PR3_Part1_A.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pg1QOio5l6Laugcyi22pCdOfutL36vx0
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import time
import os
import copy

num_epochs = 10
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
data_transforms = transforms.Compose(
     # transform image to tensor (multiple channels/dimensions)
     [transforms.Resize((224,224)),transforms.ToTensor(),
      # normalize image range from 0 and 255 to between 0 and 1
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
)

trainset = torchvision.datasets.CIFAR100('./data_set', train = True, transform = data_transforms, download=True)
testset = torchvision.datasets.CIFAR100('./data_set', train=False, transform = data_transforms, download=True)

train_data = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2) #If your OS is Windows, set num_workers be 0.
model = models.vgg16(pretrained = True)

num_ftrs=model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_ftrs, 100) # num_cls is the number of classes. Here it is the last layer, we want it to predict num_cls classes.

for param in model.parameters(): # freeze
    param.requires_grad = False
for param in model.classifier[6].parameters(): # train the last linear layer.
    param.requires_grad = True

model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

for epoch in range(num_epochs):
    # loop over mini-batch
    print('Epoch: {0}'.format(epoch))

    for data in (train_data):
        inputs = data[0].to(device)
        labels = data[1].to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

best_model_wts = copy.deepcopy(model.state_dict())
torch.save(best_model_wts , 'best_model_weight.pth')

model.load_state_dict(torch.load('best_model_weight.pth'))
test_data = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, num_workers=2) #If your OS is Windows, set num_workers be 0.

correct = 0
total = 0
for data in test_data:
  inputs, labels = data[0].to(device), data[1].to(device)
  outputs = model(inputs)
  _, predicted = torch.max(outputs.data, 1)
  total += labels.size(0)
  correct += (predicted == labels).sum().item()

print('Correct Predictions: {0}'.format(correct))
print('Total Predictions: {0}'.format(total))
print('Accuracy of the model: %d %%' % (100 * correct / total))